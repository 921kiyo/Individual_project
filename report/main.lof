\select@language {english}
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Agent and Environment\relax }}{12}{figure.caption.10}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Relationships among learning, planning and acting\relax }}{14}{figure.caption.11}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Relationships among learning, planning and acting \leavevmode {\color {red}Update this figure}\relax }}{18}{figure.caption.16}
\contentsline {figure}{\numberline {2.4}{\ignorespaces Relationships among learning, planning and acting \leavevmode {\color {red}Update this figure}\relax }}{18}{figure.caption.17}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Proposed reinforcement learning architecture. ILASP learns to generate a model and updates based on the interaction with the environment, which is used to hypothesis. \relax }}{20}{figure.caption.18}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces GAME \relax }}{26}{figure.caption.21}
\contentsline {figure}{\numberline {4.2}{\ignorespaces PLACEHOLDER\relax }}{26}{figure.caption.22}
\contentsline {figure}{\numberline {4.3}{\ignorespaces PLACEHOLDER\relax }}{27}{figure.caption.23}
\contentsline {figure}{\numberline {4.4}{\ignorespaces PLACEHOLDER\relax }}{27}{figure.caption.24}
\contentsline {figure}{\numberline {4.5}{\ignorespaces Before (left) and after (right) transfer learning\relax }}{28}{figure.caption.25}
\contentsline {figure}{\numberline {4.6}{\ignorespaces PLACEHOLDER\relax }}{28}{figure.caption.26}
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
