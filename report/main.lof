\select@language {english}
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Agent and Environment\relax }}{12}{figure.caption.10}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Relationships among learning, planning and acting\relax }}{14}{figure.caption.11}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Relationships among learning, planning and acting \leavevmode {\color {red}Update this figure}\relax }}{18}{figure.caption.16}
\contentsline {figure}{\numberline {2.4}{\ignorespaces Relationships among learning, planning and acting \leavevmode {\color {red}Update this figure}\relax }}{18}{figure.caption.17}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces VGDL game example\relax }}{19}{figure.caption.18}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Enviroment for experiment 1\relax }}{20}{figure.caption.19}
\contentsline {figure}{\numberline {3.3}{\ignorespaces Comparison of training performance between my algorithm and Q-learning\relax }}{20}{figure.caption.20}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Comparison of test performance between my algorithm and Q-learning\relax }}{21}{figure.caption.21}
\contentsline {figure}{\numberline {3.5}{\ignorespaces Enviroment for experiment 3\relax }}{22}{figure.caption.22}
\contentsline {figure}{\numberline {3.6}{\ignorespaces Comparison of training performance between my algorithm and Q-learning\relax }}{22}{figure.caption.23}
\contentsline {figure}{\numberline {3.7}{\ignorespaces Comparison of test performance between my algorithm and Q-learning\relax }}{23}{figure.caption.24}
\contentsline {figure}{\numberline {3.8}{\ignorespaces Enviroment for experiment 3 (fail)\relax }}{24}{figure.caption.26}
\contentsline {figure}{\numberline {3.9}{\ignorespaces Comparison of training performance between my algorithm and Q-learning\relax }}{24}{figure.caption.27}
\contentsline {figure}{\numberline {3.10}{\ignorespaces Comparison of test performance between my algorithm and Q-learning\relax }}{25}{figure.caption.28}
\contentsline {figure}{\numberline {3.11}{\ignorespaces Before (left) and after (right) transfer learning\relax }}{26}{figure.caption.29}
\contentsline {figure}{\numberline {3.12}{\ignorespaces Comparison of training performance between my algorithm and Q-learning (before transfer)\relax }}{26}{figure.caption.30}
\contentsline {figure}{\numberline {3.13}{\ignorespaces Comparison of test performance between my algorithm and Q-learning (before transfer)\relax }}{27}{figure.caption.31}
\contentsline {figure}{\numberline {3.14}{\ignorespaces Comparison of training performance between my algorithm and Q-learning (after transfer)\relax }}{28}{figure.caption.33}
\contentsline {figure}{\numberline {3.15}{\ignorespaces Comparison of test performance between my algorithm and Q-learning (after transfer)\relax }}{28}{figure.caption.34}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Reinforcement learning pipeline using ILASP. ILASP learns to generate a modelof the environment, or hypothesis, and updates it based on the interaction with the environment. \relax }}{29}{figure.caption.35}
\addvspace {10\p@ }
\addvspace {10\p@ }
