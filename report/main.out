\BOOKMARK [0][]{chapter.1}{1 Introduction}{}% 1
\BOOKMARK [0][]{chapter.2}{2 Background}{}% 2
\BOOKMARK [1][]{section.2.1}{2.1 Inductive Logic Programming \(ILP\)}{chapter.2}% 3
\BOOKMARK [2][]{subsection.2.1.1}{2.1.1 Stable Model Semantics}{section.2.1}% 4
\BOOKMARK [2][]{subsection.2.1.2}{2.1.2 Anwer Set Programming \(ASP\) Syntax}{section.2.1}% 5
\BOOKMARK [2][]{subsection.2.1.3}{2.1.3 ILP under Answer Set Semantics}{section.2.1}% 6
\BOOKMARK [2][]{subsection.2.1.4}{2.1.4 Inductive Learning of Answer Set Programs \(ILASP\)}{section.2.1}% 7
\BOOKMARK [1][]{section.2.2}{2.2 Reinforcement Learning \(RL\)}{chapter.2}% 8
\BOOKMARK [2][]{subsection.2.2.1}{2.2.1 Markov Decision Process \(MDP\)}{section.2.2}% 9
\BOOKMARK [2][]{subsection.2.2.2}{2.2.2 Policies and Value Functions}{section.2.2}% 10
\BOOKMARK [2][]{subsection.2.2.3}{2.2.3 Model-based and Model-free Reinforcement Learning}{section.2.2}% 11
\BOOKMARK [2][]{subsection.2.2.4}{2.2.4 Temporal-Difference \(TD\) Learning}{section.2.2}% 12
\BOOKMARK [2][]{subsection.2.2.5}{2.2.5 Function Approximation}{section.2.2}% 13
\BOOKMARK [2][]{subsection.2.2.6}{2.2.6 Transfer Learning}{section.2.2}% 14
\BOOKMARK [0][]{chapter.3}{3 Framework}{}% 15
\BOOKMARK [1][]{section.3.1}{3.1 Experience Accumulation}{chapter.3}% 16
\BOOKMARK [2][]{subsection.3.1.1}{3.1.1 State transition experience}{section.3.1}% 17
\BOOKMARK [2][]{subsection.3.1.2}{3.1.2 Environment experience}{section.3.1}% 18
\BOOKMARK [1][]{section.3.2}{3.2 Inductive Learning}{chapter.3}% 19
\BOOKMARK [2][]{subsection.3.2.1}{3.2.1 Search Space}{section.3.2}% 20
\BOOKMARK [1][]{section.3.3}{3.3 Generate a plan}{chapter.3}% 21
\BOOKMARK [1][]{section.3.4}{3.4 Plan execution}{chapter.3}% 22
\BOOKMARK [1][]{section.3.5}{3.5 Exploration}{chapter.3}% 23
\BOOKMARK [0][]{chapter.4}{4 Evaluation}{}% 24
\BOOKMARK [1][]{section.4.1}{4.1 Evaluation Metrics}{chapter.4}% 25
\BOOKMARK [2][]{subsection.4.1.1}{4.1.1 Experiment Platform}{section.4.1}% 26
\BOOKMARK [2][]{subsection.4.1.2}{4.1.2 Benchmark}{section.4.1}% 27
\BOOKMARK [2][]{subsection.4.1.3}{4.1.3 Parameters}{section.4.1}% 28
\BOOKMARK [1][]{section.4.2}{4.2 Experiment Results}{chapter.4}% 29
\BOOKMARK [2][]{subsection.4.2.1}{4.2.1 Experiment1}{section.4.2}% 30
\BOOKMARK [2][]{subsection.4.2.2}{4.2.2 Experiment2}{section.4.2}% 31
\BOOKMARK [2][]{subsection.4.2.3}{4.2.3 Experiment3}{section.4.2}% 32
\BOOKMARK [2][]{subsection.4.2.4}{4.2.4 Experiment4}{section.4.2}% 33
\BOOKMARK [2][]{subsection.4.2.5}{4.2.5 Experiment5}{section.4.2}% 34
\BOOKMARK [0][]{chapter.5}{5 Related Work}{}% 35
\BOOKMARK [0][]{chapter.6}{6 Discussion}{}% 36
\BOOKMARK [1][]{section.6.1}{6.1 Contribution}{chapter.6}% 37
\BOOKMARK [1][]{section.6.2}{6.2 Limitations}{chapter.6}% 38
\BOOKMARK [2][]{subsection.6.2.1}{6.2.1 Scalability}{section.6.2}% 39
\BOOKMARK [2][]{subsection.6.2.2}{6.2.2 Flexibility}{section.6.2}% 40
\BOOKMARK [1][]{section.6.3}{6.3 Further Research}{chapter.6}% 41
\BOOKMARK [2][]{subsection.6.3.1}{6.3.1 Value iteration approach}{section.6.3}% 42
\BOOKMARK [2][]{subsection.6.3.2}{6.3.2 Weak Constraint}{section.6.3}% 43
\BOOKMARK [2][]{subsection.6.3.3}{6.3.3 probabilistic inductive logic programming}{section.6.3}% 44
\BOOKMARK [2][]{subsection.6.3.4}{6.3.4 generalisation of the current approach}{section.6.3}% 45
\BOOKMARK [0][]{chapter.7}{7 Conclusion}{}% 46
\BOOKMARK [0][]{section*.35}{Appendices}{}% 47
\BOOKMARK [1][]{section.1..1}{.1 Ethics}{section*.35}% 48
\BOOKMARK [1][]{section.1..2}{.2 Learning tasks}{section*.35}% 49
\BOOKMARK [1][]{section.1..3}{.3 Abduction tasks}{section*.35}% 50
